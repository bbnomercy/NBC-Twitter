{"cells":[{"metadata":{},"cell_type":"raw","source":"Pada notebook ini akan menerapkan model klasifikasi teks pada data Twitter menggunakan metode Naive Bayes Classifier untuk melakukan klasifikasi tweet dalam kategori prostitusi (True) ataupun bukan prostitusi (False).\n\n\nDataset yang dimasukkan disini meliputi data training dan data testing. Ada 40000 data training yang dibagi menjadi dua bagian, yaitu data 20000 True (prostitusi) dan 20000 data False (bukan prostitusi), dan 10000 data sebagai data testing.\n\nPengujian dilakukan untuk menentukan akurasi klasifikasi metode NBC dan menggunakan Confusion Matrix"},{"metadata":{},"cell_type":"markdown","source":"Langkah pertama, persiapkan module python yang akan digunakan"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport string\nimport numpy as np\nimport nltk\nimport re\nimport random\nfrom nltk.tokenize import word_tokenize\nfrom nltk import FreqDist,classify, NaiveBayesClassifier\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import data training dan data testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_true = pd.read_excel('twitter-prostitute.xlsx')\ndata_train_false = pd.read_excel('twitter-not-prostitute.xlsx')\ndata_test = pd.read_csv('random-tweet-06052020.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_train_true.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_train_false.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Jumlah data training (True)\\t:\\t{len(data_train_true)}\")\nprint(f\"Jumlah data training (False)\\t:\\t{len(data_train_false)}\")\nprint(f\"Jumlah data test\\t\\t:\\t{len(data_test)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prostitute_tweets = data_train_true['tweet']\nnot_prostitute_tweets = data_train_false['tweet']\njust_tweets = data_test['tweet']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ambil data dari kolom tweet dari setiap file"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cleaning(text):\n\ttext = re.sub(r'<[^>]+>', '', text) #delete html tags\n\ttext = re.sub(r'\\S*twitter.com\\S*', '', text)   #delete twitter image\n\ttext = re.sub(r'https?://[A-Za-z0-9./]+','',text) #delete url\n\ttext = re.sub(r'@[A-Za-z0-9]+','',text) #delete user mention\n\ttext = re.sub(r'#[A-Za-z0-9]+','',text) #delete twitter hashtag\n\ttext = re.sub(r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)','', text) #delete number\n\ttext = re.sub(r\"[^a-zA-Z]\", \" \", text) #only accept alphabet char\n\ttext = re.sub(r\"(\\w)(\\1{2,})\", r'\\1', text) #delete repeated char\n\ttext = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text) #remove single character\n\ttext = text.lower() #change to lowercase\n\treturn text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lakukan pembersihan teks dari noise seperti, menghapus html tags, menghapus url gambar dari twitter, menghapus url, menghapus user mention, menghapus hashtag, dan mengkonversi semua huruf menjadi lowercase"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize(text):\n\t#disini diisi dengan stop words\n\tignore_words = ['by', 'yang', 'ya', 'saya', 'dia', 'ia', 'ke', 'pun', 'rt']\n\twords = text.split();\n\twords = [w for w in words if w not in ignore_words]\n\treturn words","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Melakukan tokenisasi, yaitu memecah setiap kata dalam kalimat menjadi per kata dan dimasukkan ke dalam list"},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_tweet_tokens = []\nfor i in prostitute_tweets:\n\tpositive_tweet_tokens.append(tokenize(cleaning(i)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"negative_tweet_tokens = []\nfor i in not_prostitute_tweets:\n\tnegative_tweet_tokens.append(tokenize(cleaning(i)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Buat daftar kata dari seluruh data training yang sudah melalui tahap pembersihan dan sudah dikonversi menjadi bentuk token"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_all_words(cleaned_token_list):\n\tfor tokens in cleaned_token_list:\n\t\tfor token in tokens:\n\t\t\tyield token\n\ndef get_tweets_for_model(cleaned_tokens_list):\n\tfor tweet_tokens in cleaned_tokens_list:\n\t\tyield dict([token, True] for token in tweet_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_pos_words = get_all_words(positive_tweet_tokens)\nfreq_dist_pos = FreqDist(all_pos_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Buat daftar kata beserta frekuensi kemunculan kata pada daftar seluruh kata **(Bag of words)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Kata yang sering muncul: {freq_dist_pos.most_common(5000)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_tokens_for_model = get_tweets_for_model(positive_tweet_tokens)\nnegative_tokens_for_model = get_tweets_for_model(negative_tweet_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_dataset = [(tweet_dict, \"True\")\n\t\t\t\t\t\tfor tweet_dict in positive_tokens_for_model]\nnegative_dataset = [(tweet_dict, \"False\")\n\t\t\t\t\t\tfor tweet_dict in negative_tokens_for_model]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Berikan label pada setiap kata yang termasuk dalam kategori True dan False"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = positive_dataset + negative_dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gabungkan semua daftar kata dalam sebuah list"},{"metadata":{"trusted":true},"cell_type":"code","source":"random.shuffle(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = dataset[:40000]\ntest_data = dataset[9600:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Buat alokasi data training : data testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = NaiveBayesClassifier.train(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Akurasi Klasifikasi Naive Bayes\\t:\\t\"+\"{:.2f}\".format(classify.accuracy(classifier, test_data) * 100)+\" %\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_result = []\nclassifier_result = []\n\nfor i in range(len(test_data)):\n\ttest_result.append(classifier.classify(test_data[i][0]))\n\tclassifier_result.append(test_data[i][1])\n\nc_matrix = nltk.ConfusionMatrix(classifier_result, test_result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lakukan pengujian menggunakan confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Confusion Matrix :\\n{c_matrix}\", )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = {'True', 'False'}\n\nTP, FN, FP = Counter(), Counter(), Counter()\nfor i in labels:\n\tfor j in labels:\n\t\tif i == j:\n\t\t\tTP[i] += int(c_matrix[i,j])\n\t\telse:\n\t\t\tFN[i] += int(c_matrix[i,j])\n\t\t\tFP[j] += int(c_matrix[i,j])\nprint(\"label   | precision             | recall                | f_measure         \")\nprint(\"--------+-----------------------+-----------------------+-------------------\")\nfor label in sorted(labels):\n\tprecision, recall = 0, 0\n\tif TP[label] == 0:\n\t\tf_measure = 0\n\telse:\n\t\tprecision = float(TP[label]) / (TP[label]+FP[label])\n\t\trecall = float(TP[label]) / (TP[label]+FN[label])\n\t\tf_measure = float(2) * (precision * recall) / (precision + recall)\n\tprint(f\"{label}\\t| {precision}\\t| {recall}\\t| {f_measure}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classifier.show_most_informative_features(20))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}