{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Tweet Classification for Classify Online Prostitut.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukmandev/NBC-Twitter/blob/master/Tweet%20Classification%20for%20Classify%20Online%20Prostitut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eryZlfmUnzvH",
        "colab_type": "raw"
      },
      "source": [
        "Pada notebook ini akan menerapkan model klasifikasi teks pada data Twitter menggunakan metode Naive Bayes Classifier untuk melakukan klasifikasi tweet dalam kategori prostitusi (True) ataupun bukan prostitusi (False).\n",
        "\n",
        "\n",
        "Dataset yang dimasukkan disini meliputi data training dan data testing. Ada 40000 data training yang dibagi menjadi dua bagian, yaitu data 20000 True (prostitusi) dan 20000 data False (bukan prostitusi), dan 10000 data sebagai data testing.\n",
        "\n",
        "Pengujian dilakukan untuk menentukan akurasi klasifikasi metode NBC dan menggunakan Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSP8HsN3nzvI",
        "colab_type": "text"
      },
      "source": [
        "Langkah pertama, persiapkan module python yang akan digunakan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-Luf19yynzvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import random\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist,classify, NaiveBayesClassifier\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULgQjnjcnzvN",
        "colab_type": "text"
      },
      "source": [
        "Import data training dan data testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "K_Jaoee3nzvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train_true = pd.read_excel('../content/twitter-prostitute.xlsx')\n",
        "data_train_false = pd.read_excel('../content/twitter-not-prostitute.xlsx')\n",
        "data_test = pd.read_csv('../content/random-tweet-06052020.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1c0Xiq3HnzvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5eae67f1-2928-44f9-cf01-bf1a77c80413"
      },
      "source": [
        "print(data_train_true['tweet'].head())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    AvaiL BO yaa bebüòô\\nWA 0831 9315 9762\\n#AvailJo...\n",
            "1    Include exclude Ready beb \\nWa 0831 9315 9762\\...\n",
            "2    AvaiL Jogja Minat DM ajaüòç\\nFasht Respon.\\n#Ava...\n",
            "3    MAEN SANTAI GA BURU\" \\nFULL SERVICE NO ANAL US...\n",
            "4    New bie...Ready ya..2 slot aja 085647266101\\n#...\n",
            "Name: tweet, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lmsaf6sZnzvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "addb8604-e13e-44bc-d7f8-1110c5403f4d"
      },
      "source": [
        "print(data_train_false['tweet'].head())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    Lanjutannya, siapa yang naruh bawang disini _ÔøΩ...\n",
            "1    1 Ramadan : Hari Juma'at.\\n8 Ramadan : Hari Ju...\n",
            "2    Selamat berbuka puasa kepada semuaÔøΩ_ÔøΩÔøΩÔøΩ pic.tw...\n",
            "3    Aku mau nepatin janji aku kalo taekook selca a...\n",
            "4    Bagi Bagi Saldo\\nada saldo 100k untuk 4 pemena...\n",
            "Name: tweet, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gNmNfxcWnzvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6744f031-a463-4d02-c1cb-57d08cc8fc0f"
      },
      "source": [
        "print(data_test['tweet'].head())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0                                           ko km gt:(\n",
            "1               Waktu indonesia bagian overthinking :f\n",
            "2             efek mau dapet huh kmrn w juga gitu ndoy\n",
            "3                                                Ampun\n",
            "4    Btw aku dapet ads ultah baekkie pic.twitter.co...\n",
            "Name: tweet, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WusfmB0knzvb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e031b4ed-37f6-437e-ae99-24c0667b6315"
      },
      "source": [
        "print(f\"Jumlah data training (True)\\t:\\t{len(data_train_true)}\")\n",
        "print(f\"Jumlah data training (False)\\t:\\t{len(data_train_false)}\")\n",
        "print(f\"Jumlah data test\\t\\t:\\t{len(data_test)}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jumlah data training (True)\t:\t20000\n",
            "Jumlah data training (False)\t:\t20000\n",
            "Jumlah data test\t\t:\t10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ep9oGAWPnzvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prostitute_tweets = data_train_true['tweet']\n",
        "not_prostitute_tweets = data_train_false['tweet']\n",
        "just_tweets = data_test['tweet']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omi3ZmD6nzvi",
        "colab_type": "text"
      },
      "source": [
        "Ambil data dari kolom tweet dari setiap file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "a4LIhSMsnzvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleaning(text):\n",
        "\ttext = re.sub(r'<[^>]+>', '', text) #delete html tags\n",
        "\ttext = re.sub(r'\\S*twitter.com\\S*', '', text)   #delete twitter image\n",
        "\ttext = re.sub(r'https?://[A-Za-z0-9./]+','',text) #delete url\n",
        "\ttext = re.sub(r'@[A-Za-z0-9]+','',text) #delete user mention\n",
        "\ttext = re.sub(r'#[A-Za-z0-9]+','',text) #delete twitter hashtag\n",
        "\ttext = re.sub(r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)','', text) #delete number\n",
        "\ttext = re.sub(r\"[^a-zA-Z]\", \" \", text) #only accept alphabet char\n",
        "\ttext = re.sub(r\"(\\w)(\\1{2,})\", r'\\1', text) #delete repeated char\n",
        "\ttext = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text) #remove single character\n",
        "\ttext = text.lower() #change to lowercase\n",
        "\treturn text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1DWaenJnzvp",
        "colab_type": "text"
      },
      "source": [
        "Lakukan pembersihan teks dari noise seperti, menghapus html tags, menghapus url gambar dari twitter, menghapus url, menghapus user mention, menghapus hashtag, dan mengkonversi semua huruf menjadi lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rbCaRUFunzvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "\t#disini diisi dengan stop words\n",
        "\tignore_words = ['by', 'yang', 'ya', 'saya', 'dia', 'ia', 'ke', 'pun', 'rt']\n",
        "\twords = text.split();\n",
        "\twords = [w for w in words if w not in ignore_words]\n",
        "\treturn words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn54Bgfsnzvu",
        "colab_type": "text"
      },
      "source": [
        "Melakukan tokenisasi, yaitu memecah setiap kata dalam kalimat menjadi per kata dan dimasukkan ke dalam list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VCO6QvGJnzvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive_tweet_tokens = []\n",
        "for i in prostitute_tweets:\n",
        "\tpositive_tweet_tokens.append(tokenize(cleaning(i)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v8q1UrIGnzvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "negative_tweet_tokens = []\n",
        "for i in not_prostitute_tweets:\n",
        "\tnegative_tweet_tokens.append(tokenize(cleaning(i)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM8px4EEnzv0",
        "colab_type": "text"
      },
      "source": [
        "Buat daftar kata dari seluruh data training yang sudah melalui tahap pembersihan dan sudah dikonversi menjadi bentuk token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XKG2xPIbnzv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_words(cleaned_token_list):\n",
        "\tfor tokens in cleaned_token_list:\n",
        "\t\tfor token in tokens:\n",
        "\t\t\tyield token\n",
        "\n",
        "def get_tweets_for_model(cleaned_tokens_list):\n",
        "\tfor tweet_tokens in cleaned_tokens_list:\n",
        "\t\tyield dict([token, True] for token in tweet_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "X-S8krLQnzv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_pos_words = get_all_words(positive_tweet_tokens)\n",
        "freq_dist_pos = FreqDist(all_pos_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cruX4p2Inzv5",
        "colab_type": "text"
      },
      "source": [
        "Buat daftar kata beserta frekuensi kemunculan kata pada daftar seluruh kata **(Bag of words)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hfc4q5Qvnzv6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9bffca08-9771-47ce-984b-7e8d841493a2"
      },
      "source": [
        "print(f\"Kata yang sering muncul: {freq_dist_pos.most_common(100)}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kata yang sering muncul: [('wa', 11387), ('open', 7716), ('dm', 6011), ('bo', 5391), ('ready', 5356), ('jogja', 4876), ('rr', 3333), ('avail', 3211), ('say', 3121), ('slot', 2941), ('yuk', 2931), ('cod', 2567), ('beb', 2524), ('dp', 2364), ('no', 2264), ('include', 2124), ('vcs', 2123), ('ini', 1876), ('info', 1874), ('minat', 1853), ('hotel', 1631), ('exclude', 1590), ('di', 1573), ('sayang', 1533), ('st', 1490), ('isi', 1468), ('area', 1459), ('inc', 1345), ('lt', 1344), ('malam', 1279), ('exc', 1278), ('yg', 1223), ('aja', 1210), ('langsung', 1200), ('masih', 1105), ('jam', 1064), ('expo', 1001), ('chat', 967), ('promo', 943), ('via', 906), ('bisa', 894), ('real', 878), ('kak', 859), ('serius', 835), ('khusus', 804), ('buat', 789), ('wajib', 783), ('cancel', 747), ('hari', 742), ('yaa', 736), ('mau', 707), ('bio', 678), ('or', 633), ('ga', 621), ('aku', 606), ('cocok', 594), ('main', 590), ('crot', 575), ('incld', 530), ('harga', 519), ('merapat', 515), ('lagi', 503), ('fast', 494), ('excl', 493), ('sama', 492), ('ada', 487), ('slotnya', 472), ('respon', 460), ('sini', 459), ('massage', 457), ('bebas', 450), ('nya', 444), ('cash', 443), ('morning', 437), ('free', 429), ('buruan', 421), ('cek', 419), ('openbojogja', 396), ('damai', 396), ('sex', 391), ('gfe', 371), ('pacar', 369), ('room', 363), ('yogyakarta', 361), ('dan', 358), ('nih', 350), ('panlok', 338), ('chatt', 338), ('bra', 325), ('bb', 322), ('privat', 322), ('enak', 321), ('tb', 319), ('rate', 316), ('new', 314), ('pijat', 308), ('ni', 303), ('juga', 298), ('udah', 298), ('kota', 298)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GAICyEdKnzv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive_tokens_for_model = get_tweets_for_model(positive_tweet_tokens)\n",
        "negative_tokens_for_model = get_tweets_for_model(negative_tweet_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UEVPSnqunzwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive_dataset = [(tweet_dict, \"True\")\n",
        "\t\t\t\t\t\tfor tweet_dict in positive_tokens_for_model]\n",
        "negative_dataset = [(tweet_dict, \"False\")\n",
        "\t\t\t\t\t\tfor tweet_dict in negative_tokens_for_model]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vRHsw8LnzwE",
        "colab_type": "text"
      },
      "source": [
        "Berikan label pada setiap kata yang termasuk dalam kategori True dan False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "da-Mfm2OnzwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = positive_dataset + negative_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNvbPRecnzwG",
        "colab_type": "text"
      },
      "source": [
        "Gabungkan semua daftar kata dalam sebuah list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kAt0K-ybnzwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.shuffle(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4NaX_n1nnzwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = dataset[:40000]\n",
        "test_data = dataset[9600:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNwfX7uQnzwL",
        "colab_type": "text"
      },
      "source": [
        "Buat alokasi data training : data testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "H76P2RAonzwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = NaiveBayesClassifier.train(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qPX3wCHBnzwP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50638b5d-f2e6-478d-d1e5-c6f2be74698a"
      },
      "source": [
        "print(\"Akurasi Klasifikasi Naive Bayes\\t:\\t\"+\"{:.2f}\".format(classify.accuracy(classifier, test_data) * 100)+\" %\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akurasi Klasifikasi Naive Bayes\t:\t98.61 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b3Zd-TxmnzwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_result = []\n",
        "classifier_result = []\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "\ttest_result.append(classifier.classify(test_data[i][0]))\n",
        "\tclassifier_result.append(test_data[i][1])\n",
        "\n",
        "c_matrix = nltk.ConfusionMatrix(classifier_result, test_result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbnk_yxqnzwT",
        "colab_type": "text"
      },
      "source": [
        "Lakukan pengujian menggunakan confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "E_2qMuO1nzwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "dbb6dbab-c076-48a6-e101-c087e6ae493a"
      },
      "source": [
        "print(f\"Confusion Matrix :\\n{c_matrix}\", )"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "      |     F       |\n",
            "      |     a     T |\n",
            "      |     l     r |\n",
            "      |     s     u |\n",
            "      |     e     e |\n",
            "------+-------------+\n",
            "False |<15122>   31 |\n",
            " True |   393<14854>|\n",
            "------+-------------+\n",
            "(row = reference; col = test)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EomLZ-5pnzwW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2c5fa995-e476-4501-c8be-c2d441b03441"
      },
      "source": [
        "labels = {'True', 'False'}\n",
        "\n",
        "TP, FN, FP = Counter(), Counter(), Counter()\n",
        "for i in labels:\n",
        "\tfor j in labels:\n",
        "\t\tif i == j:\n",
        "\t\t\tTP[i] += int(c_matrix[i,j])\n",
        "\t\telse:\n",
        "\t\t\tFN[i] += int(c_matrix[i,j])\n",
        "\t\t\tFP[j] += int(c_matrix[i,j])\n",
        "print(\"label   | precision             | recall                | f_measure         \")\n",
        "print(\"--------+-----------------------+-----------------------+-------------------\")\n",
        "for label in sorted(labels):\n",
        "\tprecision, recall = 0, 0\n",
        "\tif TP[label] == 0:\n",
        "\t\tf_measure = 0\n",
        "\telse:\n",
        "\t\tprecision = float(TP[label]) / (TP[label]+FP[label])\n",
        "\t\trecall = float(TP[label]) / (TP[label]+FN[label])\n",
        "\t\tf_measure = float(2) * (precision * recall) / (precision + recall)\n",
        "\tprint(f\"{label}\\t| {precision}\\t| {recall}\\t| {f_measure}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label   | precision             | recall                | f_measure         \n",
            "--------+-----------------------+-----------------------+-------------------\n",
            "False\t| 0.9746696745085401\t| 0.9979542004883521\t| 0.9861745141515587\n",
            "True\t| 0.9979173664763185\t| 0.9742244375942808\t| 0.9859285809106597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4N_y1uRLnzwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "855f9d6d-525d-4c23-917f-fd78a0ecb6c8"
      },
      "source": [
        "print(classifier.show_most_informative_features(20))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "                      bo = True             True : False  =    910.3 : 1.0\n",
            "                    baik = True            False : True   =    450.3 : 1.0\n",
            "                 twitter = True            False : True   =    413.0 : 1.0\n",
            "                 content = True            False : True   =    367.0 : 1.0\n",
            "                     exc = True             True : False  =    365.0 : 1.0\n",
            "                    saat = True            False : True   =    350.3 : 1.0\n",
            "                 slotnya = True             True : False  =    315.0 : 1.0\n",
            "                    like = True            False : True   =    309.7 : 1.0\n",
            "                   salah = True            False : True   =    308.3 : 1.0\n",
            "                      rr = True             True : False  =    266.3 : 1.0\n",
            "                 menjadi = True            False : True   =    265.0 : 1.0\n",
            "                  mereka = True            False : True   =    250.6 : 1.0\n",
            "                 include = True             True : False  =    249.8 : 1.0\n",
            "                      tu = True            False : True   =    248.6 : 1.0\n",
            "               indonesia = True            False : True   =    245.0 : 1.0\n",
            "                     inc = True             True : False  =    244.6 : 1.0\n",
            "                      lt = True             True : False  =    244.5 : 1.0\n",
            "                   sebab = True            False : True   =    239.7 : 1.0\n",
            "                    kata = True            False : True   =    221.0 : 1.0\n",
            "                  kenapa = True            False : True   =    221.0 : 1.0\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}