{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lukmandev/NBC-Twitter/blob/master/Naive_Bayes_Text_Classification_Tweet_Prostitute_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BEZR_UZS-apx"
   },
   "source": [
    "Pada notebook ini menampilkan metode klasifikasi dokumen teks menggunakan metode Naive Bayes untuk melakukan prediksi data twitter yang termasuk dalam kategori prostitusi atau bukan prostitusi.\n",
    "\n",
    "Dataset diambil dari twitter sebanyak 40000 data termasuk dalam kategori true (prostitusi) sebanyak 20000 dan false (bukan prostitusi) sebanyak 20000 data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3A580Hn-_F05"
   },
   "source": [
    "Pertama, import modul python yang digunakan untuk proses preprocessing dan pembuatan model untuk dilakukan klasifikasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WrnLxI6H-Phi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBpIw1Vj_ahS"
   },
   "source": [
    "Import semua dataset yang akan dilakukan klasifikasi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SLD6cnM_lLr"
   },
   "outputs": [],
   "source": [
    "data_train_true = pd.read_excel('twitter-prostitute.xlsx')\n",
    "data_train_false = pd.read_excel('twitter-not-prostitute.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mVZEK9Jo_5tO"
   },
   "source": [
    "Gabungkan data true (prostitute) dan data false (not prostitute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TgZjF7bW_vGN"
   },
   "outputs": [],
   "source": [
    "dataset = pd.concat([data_train_true, data_train_false], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "aA6Zcud9_9i8",
    "outputId": "c357bdc7-faa7-4cd8-de09-c16667be454f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                 date       username  \\\n",
      "0  1255052854739398658  2020-04-28 00:00:00   rina11091996   \n",
      "1  1255052799798202373  2020-04-28 00:00:00   rina11091996   \n",
      "2  1255052613646573569  2020-04-28 00:00:00  viollasyantik   \n",
      "3  1255052558667661312  2020-04-28 00:00:00    lyannyhijab   \n",
      "4  1255052557061287938  2020-04-28 00:00:00      dheajogja   \n",
      "\n",
      "                                               tweet  status  \n",
      "0  AvaiL BO yaa bebüòô\\nWA 0831 9315 9762\\n#AvailJo...       1  \n",
      "1  Include exclude Ready beb \\nWa 0831 9315 9762\\...       1  \n",
      "2  AvaiL Jogja Minat DM ajaüòç\\nFasht Respon.\\n#Ava...       1  \n",
      "3  MAEN SANTAI GA BURU\" \\nFULL SERVICE NO ANAL US...       1  \n",
      "4  New bie...Ready ya..2 slot aja 085647266101\\n#...       1  \n"
     ]
    }
   ],
   "source": [
    "print(dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "jdhVwFx8ADg3",
    "outputId": "dd258450-9676-4691-a176-22e698b0521a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    AvaiL BO yaa bebüòô\\nWA 0831 9315 9762\\n#AvailJo...\n",
      "1    Include exclude Ready beb \\nWa 0831 9315 9762\\...\n",
      "2    AvaiL Jogja Minat DM ajaüòç\\nFasht Respon.\\n#Ava...\n",
      "3    MAEN SANTAI GA BURU\" \\nFULL SERVICE NO ANAL US...\n",
      "4    New bie...Ready ya..2 slot aja 085647266101\\n#...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset['tweet'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SdKJJ2rRAJzT",
    "outputId": "79d099e9-a21d-4b6d-85a7-d6cdacc9885f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZaMpn8SuAPUm"
   },
   "source": [
    "Setelah data berhasil dibuka, saatnya melakukan preprocessing pada teks. Yang akan dilakukan preprocessing yaitu data pada kolom **tweet** dimana data ini berisi tweet yang diambil dari twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDjaYQaQAjkg"
   },
   "source": [
    "Ada beberapa process preprocessing yaitu cleaning text atau membersihkan text dari noise dan tokenizing yaitu memecah semua text menjadi per kata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YaI99UbMAi6s"
   },
   "outputs": [],
   "source": [
    "stopwords_file = open(\"stopwords-id.txt\", 'r')\n",
    "stopwords = [x.strip() for x in stopwords_file.readlines()]\n",
    "stopwords.extend(['by', 'rt', 'via'])\n",
    "\n",
    "def cleaning(text):\n",
    "\ttext = re.sub(r'<[^>]+>', '', text) #delete html tags\n",
    "\ttext = re.sub(r'\\S*twitter.com\\S*', '', text)   #delete twitter image\n",
    "\ttext = re.sub(r'https?://[A-Za-z0-9./]+','',text) #delete url\n",
    "\ttext = re.sub(r'@[A-Za-z0-9]+','',text) #delete user mention\n",
    "\ttext = re.sub(r'#[A-Za-z0-9]+','',text) #delete twitter hashtag\n",
    "\ttext = re.sub(r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)','', text) #delete number\n",
    "\ttext = re.sub(r\"[^a-zA-Z]\", \" \", text) #only accept alphabet char\n",
    "\ttext = re.sub(r\"(\\w)(\\1{2,})\", r'\\1', text) #delete repeated char\n",
    "\ttext = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text) #remove single character\n",
    "\ttext = text.lower() #change to lowercase\n",
    "\ttext = stemmer.stem(text) #stemming\n",
    "\treturn text\n",
    "\n",
    "def tokenize(text):\n",
    "\t#disini diisi dengan stop words\n",
    "\twords = text.split();\n",
    "\twords = [w for w in words if w not in stopwords]\n",
    "\treturn words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYICDfwJBS5Z"
   },
   "source": [
    "Cleaning text pada data tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WF58mtJANuS"
   },
   "outputs": [],
   "source": [
    "dataset['tweet'] = dataset.tweet.map(lambda x: cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "5EdgUnlaBd1Q",
    "outputId": "5f9a098c-c66c-48a3-b669-b9bb7c327b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                  avail bo yaa beb wa\n",
      "1                         include exclude ready beb wa\n",
      "2                avail jogja minat dm aja fasht respon\n",
      "3    maen santai ga buru full service no anal use caps\n",
      "4                            new bie ready ya slot aja\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset['tweet'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SzotiJo9BlFh"
   },
   "source": [
    "Tokenizing text pada data tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tcygac3MBjgR"
   },
   "outputs": [],
   "source": [
    "dataset['tweet'] = dataset.tweet.apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "cbDgZz10Brw0",
    "outputId": "582b0ac4-1cd2-45a1-9c8f-703d25cd15a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                            [avail, bo, yaa, beb, wa]\n",
      "1                   [include, exclude, ready, beb, wa]\n",
      "2        [avail, jogja, minat, dm, aja, fasht, respon]\n",
      "3    [maen, santai, ga, buru, full, service, no, an...\n",
      "4                     [new, bie, ready, ya, slot, aja]\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset['tweet'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MUVEJk8PBw2x"
   },
   "source": [
    "Menggabungkan semua tweet menggunakan spasi untuk dilakukan tahap selanjutnya yaitu pembuatan vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8REtg1qVB7vI"
   },
   "outputs": [],
   "source": [
    "dataset['tweet'] = dataset.tweet.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPfEVYL6CARh"
   },
   "source": [
    "Memasukkan label ke array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTep37EIB-B1"
   },
   "outputs": [],
   "source": [
    "dataset['label'] = dataset.status.map(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqXWGfq3CJdB"
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "counts = count_vect.fit_transform(dataset['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "LpGsFwGgCNz0",
    "outputId": "b6103963-78b2-4a23-c192-8b639cf4d9f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1580)\t1\n",
      "  (0, 3027)\t1\n",
      "  (0, 27875)\t1\n",
      "  (0, 2240)\t1\n",
      "  (0, 27195)\t1\n",
      "  (1, 2240)\t1\n",
      "  (1, 27195)\t1\n",
      "  (1, 10127)\t1\n",
      "  (1, 7044)\t1\n",
      "  (1, 20865)\t1\n",
      "  (2, 1580)\t1\n",
      "  (2, 11145)\t1\n",
      "  (2, 15754)\t1\n",
      "  (2, 6087)\t1\n",
      "  (2, 444)\t1\n",
      "  (2, 7244)\t1\n",
      "  (2, 21200)\t1\n",
      "  (3, 14462)\t1\n",
      "  (3, 22030)\t1\n",
      "  (3, 7788)\t1\n",
      "  (3, 3578)\t1\n",
      "  (3, 7738)\t1\n",
      "  (3, 22835)\t1\n",
      "  (3, 17619)\t1\n",
      "  (3, 879)\t1\n",
      "  (3, 26835)\t1\n",
      "  (3, 3787)\t1\n",
      "  (4, 20865)\t1\n",
      "  (4, 444)\t1\n",
      "  (4, 16945)\t1\n",
      "  (4, 2742)\t1\n",
      "  (4, 27874)\t1\n",
      "  (4, 23503)\t1\n"
     ]
    }
   ],
   "source": [
    "print(counts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nFJBIp8pCWeY"
   },
   "source": [
    "Disini mentransformasikan semua feature kata menggunakan TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRW07JgoCSpU"
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer().fit(counts)\n",
    "counts = transformer.transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "qOD4BWEeCcCB",
    "outputId": "b3e4a9d1-9c85-4cb7-d5b3-281b306571b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 27875)\t0.5911705953129078\n",
      "  (0, 27195)\t0.2822194474686629\n",
      "  (0, 3027)\t0.3843499205847922\n",
      "  (0, 2240)\t0.47674485769290337\n",
      "  (0, 1580)\t0.44255958911507276\n",
      "  (1, 27195)\t0.2866682929106074\n",
      "  (1, 20865)\t0.38428108764986996\n",
      "  (1, 10127)\t0.49885978763514066\n",
      "  (1, 7044)\t0.5355187636154758\n",
      "  (1, 2240)\t0.4842601590165411\n",
      "  (2, 21200)\t0.3753169580936991\n",
      "  (2, 15754)\t0.27032017850061374\n",
      "  (2, 11145)\t0.2156594729911206\n",
      "  (2, 7244)\t0.7575121245337826\n",
      "  (2, 6087)\t0.18561664533035457\n",
      "  (2, 1580)\t0.24615315912467356\n",
      "  (2, 444)\t0.2658677080531679\n",
      "  (3, 26835)\t0.3987895175091566\n",
      "  (3, 22835)\t0.3340995998990038\n",
      "  (3, 22030)\t0.2971735280329197\n",
      "  (3, 17619)\t0.18397171528605755\n",
      "  (3, 14462)\t0.38405376089842264\n",
      "  (3, 7788)\t0.20809474894554508\n",
      "  (3, 7738)\t0.2971735280329197\n",
      "  (3, 3787)\t0.3588993202178047\n",
      "  (3, 3578)\t0.2611730028167115\n",
      "  (3, 879)\t0.36201353464718405\n",
      "  (4, 27874)\t0.21768241478277015\n",
      "  (4, 23503)\t0.2879370816285136\n",
      "  (4, 20865)\t0.23767142901177377\n",
      "  (4, 16945)\t0.4494329267607444\n",
      "  (4, 2742)\t0.7218379145895729\n",
      "  (4, 444)\t0.30029812612360063\n"
     ]
    }
   ],
   "source": [
    "print(counts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ERknZNC9Cjlp"
   },
   "source": [
    "Kemudian setelah semua kata memiliki bobot tersendiri sesuai dengan transformasi vektor TF IDF, disini pembagian data training dan data testing dengan alokasi 80% train:20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jny-qus6CjVK"
   },
   "outputs": [],
   "source": [
    "feature_train, feature_test, target_train, target_test = train_test_split(counts, dataset['label'], train_size=0.8, test_size=0.2, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_cj-KPmdC2K8"
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(feature_train, target_train)\n",
    "predicted = model.predict(feature_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f78RGFmWC8hh"
   },
   "source": [
    "Untuk menghitung akurasi model yang sudah dibuat, dapat menggunakan accuracy_score dari scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFCSWoy9C6_m"
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(target_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "86kft79mDEqg",
    "outputId": "4390d342-8948-4b7a-d6d7-e2c8778d983c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy : 98.45%\n"
     ]
    }
   ],
   "source": [
    "print(f'Naive Bayes Accuracy : {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1zLtNNb2DKg1"
   },
   "source": [
    "Untuk pengujian, menggunakan confusion matrix sebagai berikut ini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o37R503UDIgR"
   },
   "outputs": [],
   "source": [
    "c_matrix = pd.DataFrame(\n",
    "    confusion_matrix(target_test, predicted, labels=[1, 0]),\n",
    "    index = ['Actual:True', 'Actual:False'],\n",
    "    columns = ['Pred:True', 'Pred:False']\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "np0A8yymDgbP",
    "outputId": "8b7a98ee-c225-4933-b676-1b15de780810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Pred:True  Pred:False\n",
      "Actual:True        3928          59\n",
      "Actual:False         65        3948\n"
     ]
    }
   ],
   "source": [
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UM2UJUThDldR"
   },
   "source": [
    "Untuk melihat laporan klasifikasi, menggunakan classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nsp938bxDuXr"
   },
   "outputs": [],
   "source": [
    "c_report = classification_report(target_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "-WupjV2IDwD7",
    "outputId": "4794c0b4-945a-4201-f24a-5d6d8fe59083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      4013\n",
      "           1       0.98      0.99      0.98      3987\n",
      "\n",
      "    accuracy                           0.98      8000\n",
      "   macro avg       0.98      0.98      0.98      8000\n",
      "weighted avg       0.98      0.98      0.98      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(c_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WZuE2qqw0B9S"
   },
   "source": [
    "Kemudian kita lakukan prediksi data untuk data baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n1u1TLze0BA1",
    "outputId": "f90f09ee-72a9-4b0f-de61-62a93baec46d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False (Not Prostitute)\n"
     ]
    }
   ],
   "source": [
    "def pred_text(score):\n",
    "  if score == 0:\n",
    "    return 'False (Not Prostitute)'\n",
    "  else:\n",
    "    return 'True (Prostitute)'\n",
    "\n",
    "input_text = 'Semoga covid-19 ini segera berakhir dan semua kegiatan dapat kembali seperti sedia kala'\n",
    "input_text = tokenize(cleaning(input_text))\n",
    "new_counts = count_vect.transform(input_text)\n",
    "pred = model.predict(new_counts)\n",
    "print(pred_text(pred[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5TMqQCYd1YYD",
    "outputId": "221ab490-3753-42a2-83f9-7f804bd0f8bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True (Prostitute)\n"
     ]
    }
   ],
   "source": [
    "input_text = 'area #Jogja cod no dp free cancel include room'\n",
    "input_text = tokenize(cleaning(input_text))\n",
    "new_counts = count_vect.transform(input_text)\n",
    "pred = model.predict(new_counts)\n",
    "print(pred_text(pred[0]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO75D/uUhKx5e3/YVPd/l73",
   "include_colab_link": true,
   "name": "Naive Bayes Text Classification - Tweet Prostitute Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
